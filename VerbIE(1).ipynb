{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import textacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "from spacy import displacy\n",
    "from spacy.compat import *\n",
    "from textacy import *\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "import operator\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from cytoolz import itertoolz\n",
    "from spacy.parts_of_speech import CONJ, DET, NOUN, VERB\n",
    "from spacy.tokens.span import Span as SpacySpan\n",
    "\n",
    "from textacy import compat\n",
    "from textacy import constants\n",
    "from textacy import spacy_utils\n",
    "from textacy import text_utils\n",
    "\n",
    "#import PyPDF2\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import xlrd\n",
    "from xlrd import open_workbook\n",
    "from itertools import chain,combinations\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "from cytoolz import itertoolz\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from spacy.tokens.span import Span as SpacySpan\n",
    "from spacy.tokens.token import Token as SpacyToken\n",
    "\n",
    "from textacy.compat import unicode_\n",
    "from textacy import extract\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from itertools import takewhile\n",
    "from spacy.parts_of_speech import NOUN, PROPN, VERB\n",
    "from spacy.tokens.token import Token as SpacyToken\n",
    "from spacy.tokens.span import Span as SpacySpan\n",
    "\n",
    "from textacy.text_utils import is_acronym\n",
    "from textacy.constants import AUX_DEPS, SUBJ_DEPS, OBJ_DEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbieproc(document):\n",
    "    \n",
    "    \n",
    "    AUX_DEPS1 = {'aux', 'auxpass', 'neg', 'advmod','prt'}\n",
    "    OBJ_DEPS1 = {'attr', 'dative', 'dobj', 'oprd', 'npadvmod'}\n",
    "   \n",
    "    def words(doc,\n",
    "              filter_stops=True, filter_punct=True, filter_nums=False,\n",
    "              include_pos=None, exclude_pos=None, min_freq=1):\n",
    "        \"\"\"\n",
    "        Extract an ordered sequence of words from a document processed by spaCy,\n",
    "        optionally filtering words by part-of-speech tag and frequency.\n",
    "        Args:\n",
    "            doc (``textacy.Doc``, ``spacy.Doc``, or ``spacy.Span``)\n",
    "            filter_stops (bool): if True, remove stop words from word list\n",
    "            filter_punct (bool): if True, remove punctuation from word list\n",
    "            filter_nums (bool): if True, remove number-like words (e.g. 10, 'ten')\n",
    "                from word list\n",
    "            include_pos (str or Set[str]): remove words whose part-of-speech tag\n",
    "                IS NOT included in this param\n",
    "            exclude_pos (str or Set[str]): remove words whose part-of-speech tag\n",
    "                IS in the specified tags\n",
    "            min_freq (int): remove words that occur in `doc` fewer than\n",
    "                `min_freq` times\n",
    "        Yields:\n",
    "            ``spacy.Token``: the next token from ``doc`` passing specified filters\n",
    "            in order of appearance in the document\n",
    "        Raises:\n",
    "            TypeError: if `include_pos` or `exclude_pos` is not a str, a set of str,\n",
    "                or a falsy value\n",
    "        Note:\n",
    "            Filtering by part-of-speech tag uses the universal POS tag set,\n",
    "            http://universaldependencies.org/u/pos/.\n",
    "        \"\"\"\n",
    "        words_ = (w for w in doc if not w.is_space)\n",
    "        if filter_stops is True:\n",
    "            words_ = (w for w in words_ if not w.is_stop)\n",
    "        if filter_punct is True:\n",
    "            words_ = (w for w in words_ if not w.is_punct)\n",
    "        if filter_nums is True:\n",
    "            words_ = (w for w in words_ if not w.like_num)\n",
    "        if include_pos:\n",
    "            if isinstance(include_pos, compat.unicode_):\n",
    "                include_pos = include_pos.upper()\n",
    "                words_ = (w for w in words_ if w.pos_ == include_pos)\n",
    "            elif isinstance(include_pos, (set, frozenset, list, tuple)):\n",
    "                include_pos = {pos.upper() for pos in include_pos}\n",
    "                words_ = (w for w in words_ if w.pos_ in include_pos)\n",
    "            else:\n",
    "                msg = 'invalid `include_pos` type: \"{}\"'.format(type(include_pos))\n",
    "                raise TypeError(msg)\n",
    "        if exclude_pos:\n",
    "            if isinstance(exclude_pos, compat.unicode_):\n",
    "                exclude_pos = exclude_pos.upper()\n",
    "                words_ = (w for w in words_ if w.pos_ != exclude_pos)\n",
    "            elif isinstance(exclude_pos, (set, frozenset, list, tuple)):\n",
    "                exclude_pos = {pos.upper() for pos in exclude_pos}\n",
    "                words_ = (w for w in words_ if w.pos_ not in exclude_pos)\n",
    "            else:\n",
    "                msg = 'invalid `exclude_pos` type: \"{}\"'.format(type(exclude_pos))\n",
    "                raise TypeError(msg)\n",
    "        if min_freq > 1:\n",
    "            words_ = list(words_)\n",
    "            freqs = itertoolz.frequencies(w.lower_ for w in words_)\n",
    "            words_ = (w for w in words_\n",
    "                      if freqs[w.lower_] >= min_freq)\n",
    "\n",
    "        for word in words_:\n",
    "            yield word\n",
    "\n",
    "    def noun_chunks(doc, drop_determiners=True, min_freq=1):\n",
    "        \"\"\"\n",
    "        Extract an ordered sequence of noun chunks from a spacy-parsed doc, optionally\n",
    "        filtering by frequency and dropping leading determiners.\n",
    "        Args:\n",
    "            doc (``textacy.Doc`` or ``spacy.Doc``)\n",
    "            drop_determiners (bool): remove leading determiners (e.g. \"the\")\n",
    "                from phrases (e.g. \"the quick brown fox\" => \"quick brown fox\")\n",
    "            min_freq (int): remove chunks that occur in `doc` fewer than\n",
    "                `min_freq` times\n",
    "        Yields:\n",
    "            ``spacy.Span``: the next noun chunk from ``doc`` in order of appearance\n",
    "            in the document\n",
    "        \"\"\"\n",
    "        if hasattr(doc, 'spacy_doc'):\n",
    "            ncs = doc.spacy_doc.noun_chunks\n",
    "        else:\n",
    "            ncs = doc.noun_chunks\n",
    "        if drop_determiners is True:\n",
    "            ncs = (nc if nc[0].pos != DET else nc[1:]\n",
    "                   for nc in ncs)\n",
    "        if min_freq > 1:\n",
    "            ncs = list(ncs)\n",
    "            freqs = itertoolz.frequencies(nc.lower_ for nc in ncs)\n",
    "            ncs = (nc for nc in ncs\n",
    "                   if freqs[nc.lower_] >= min_freq)\n",
    "\n",
    "        for nc in ncs:\n",
    "            yield nc\n",
    "\n",
    "\n",
    "    def pos_regex_matches(doc, pattern):\n",
    "        \"\"\"\n",
    "        Extract sequences of consecutive tokens from a spacy-parsed doc whose\n",
    "        part-of-speech tags match the specified regex pattern.\n",
    "        Args:\n",
    "            doc (``textacy.Doc`` or ``spacy.Doc`` or ``spacy.Span``)\n",
    "            pattern (str): Pattern of consecutive POS tags whose corresponding words\n",
    "                are to be extracted, inspired by the regex patterns used in NLTK's\n",
    "                `nltk.chunk.regexp`. Tags are uppercase, from the universal tag set;\n",
    "                delimited by < and >, which are basically converted to parentheses\n",
    "                with spaces as needed to correctly extract matching word sequences;\n",
    "                white space in the input doesn't matter.\n",
    "                Examples (see ``constants.POS_REGEX_PATTERNS``):\n",
    "                * noun phrase: r'<DET>? (<NOUN>+ <ADP|CONJ>)* <NOUN>+'\n",
    "                * compound nouns: r'<NOUN>+'\n",
    "                * verb phrase: r'<VERB>?<ADV>*<VERB>+'\n",
    "                * prepositional phrase: r'<PREP> <DET>? (<NOUN>+<ADP>)* <NOUN>+'\n",
    "        Yields:\n",
    "            ``spacy.Span``: the next span of consecutive tokens from ``doc`` whose\n",
    "            parts-of-speech match ``pattern``, in order of apperance\n",
    "        \"\"\"\n",
    "        # standardize and transform the regular expression pattern...\n",
    "        pattern = re.sub(r'\\s', '', pattern)\n",
    "        pattern = re.sub(r'<([A-Z]+)\\|([A-Z]+)>', r'( (\\1|\\2))', pattern)\n",
    "        pattern = re.sub(r'<([A-Z]+)>', r'( \\1)', pattern)\n",
    "\n",
    "        tags = ' ' + ' '.join(tok.pos_ for tok in doc)\n",
    "\n",
    "        for m in re.finditer(pattern, tags):\n",
    "            yield doc[tags[0:m.start()].count(' '):tags[0:m.end()].count(' ')]\n",
    "\n",
    "\n",
    "    def subject_verb_object_triples(doc):\n",
    "        \"\"\"\n",
    "        Extract an ordered sequence of subject-verb-object (SVO) triples from a\n",
    "        spacy-parsed doc. Note that this only works for SVO languages.\n",
    "        Args:\n",
    "            doc (``textacy.Doc`` or ``spacy.Doc`` or ``spacy.Span``)\n",
    "        Yields:\n",
    "            Tuple[``spacy.Span``, ``spacy.Span``, ``spacy.Span``]: The next 3-tuple\n",
    "            of spans from ``doc`` representing a (subject, verb, object) triple,\n",
    "            in order of appearance.\n",
    "        \"\"\"\n",
    "        # TODO: What to do about questions, where it may be VSO instead of SVO?\n",
    "        # TODO: What about non-adjacent verb negations?\n",
    "        # TODO: What about object (noun) negations?\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            for verb in verbs:\n",
    "                subjs = spacy_utils.get_subjects_of_verb(verb)\n",
    "                if not subjs:\n",
    "                    continue\n",
    "                objs = spacy_utils.get_objects_of_verb(verb)\n",
    "                if not objs:\n",
    "                    continue\n",
    "\n",
    "                # add adjacent auxiliaries to verbs, for context\n",
    "                # and add compounds to compound nouns\n",
    "                verb_span = spacy_utils.get_span_for_verb_auxiliaries(verb)\n",
    "                verb = sent[verb_span[0] - start_i: verb_span[1] - start_i + 1]\n",
    "                for subj in subjs:\n",
    "                    subj = sent[spacy_utils.get_span_for_compound_noun(subj)[0] - start_i: subj.i - start_i + 1]\n",
    "                    for obj in objs:\n",
    "                        if obj.pos == NOUN:\n",
    "                            span = spacy_utils.get_span_for_compound_noun(obj)\n",
    "                        elif obj.pos == VERB:\n",
    "                            span = spacy_utils.get_span_for_verb_auxiliaries(obj)\n",
    "                        else:\n",
    "                            span = (obj.i, obj.i)\n",
    "                        obj = sent[span[0] - start_i: span[1] - start_i + 1]\n",
    "\n",
    "                        yield (subj, verb, obj)\n",
    "\n",
    "    def get_span_for_compound_noun(noun):\n",
    "        \"\"\"\n",
    "        Return document indexes spanning all (adjacent) tokens\n",
    "        in a compound noun.\n",
    "        \"\"\"\n",
    "        min_i = noun.i - sum(1 for _ in takewhile(lambda x: x.dep_ in ['compound','amod'],\n",
    "                                                  reversed(list(noun.lefts))))\n",
    "        return (min_i, noun.i)\n",
    "\n",
    "    def get_span_for_verb_auxiliaries(verb):\n",
    "        \"\"\"\n",
    "        Return document indexes spanning all (adjacent) tokens\n",
    "        around a verb that are auxiliary verbs or negations.\n",
    "        \"\"\"\n",
    "        min_i = verb.i - sum(1 for _ in takewhile(lambda x: x.dep_ in AUX_DEPS1,\n",
    "                                                  reversed(list(verb.lefts))))\n",
    "        max_i = verb.i + sum(1 for _ in takewhile(lambda x: x.dep_ in AUX_DEPS1,\n",
    "                                                  verb.rights))\n",
    "        return (min_i, max_i)\n",
    "\n",
    "\n",
    "    def flatten( alist ):\n",
    "        newlist = []\n",
    "        for item in alist:\n",
    "            if isinstance(item, list):\n",
    "                newlist = newlist + flatten(item)\n",
    "            else:\n",
    "                newlist.append(item)\n",
    "        return newlist\n",
    "\n",
    "    def _get_conjunctsv(tok):\n",
    "        \"\"\"\n",
    "        Return conjunct dependents of the leftmost conjunct in a coordinated phrase,\n",
    "        e.g. \"Burton, [Dan], and [Josh] ...\".\n",
    "        \"\"\"\n",
    "        return [right for right in tok.rights\n",
    "                if right.dep_ == 'conj']\n",
    "               #if right.dep_ == 'conj' and right.pos == VERB]\n",
    "\n",
    "    def _get_conjunctsn(tok):\n",
    "        \"\"\"\n",
    "        Return conjunct dependents of the leftmost conjunct in a coordinated phrase,\n",
    "        e.g. \"Burton, [Dan], and [Josh] ...\".\n",
    "        \"\"\"\n",
    "        return [right for right in tok.rights\n",
    "                if right.dep_ == 'conj']\n",
    "               #if right.dep_ == 'conj' and right.pos == NOUN]\n",
    "\n",
    "    def get_subjects_of_sent(sent):\n",
    "        \"\"\"Return the main subjects in a sentence.\"\"\"\n",
    "        subjs = [tok for tok in sent\n",
    "                 if tok.dep_ in SUBJ_DEPS]\n",
    "        # get additional conjunct subjects\n",
    "        subjs.extend(tok for subj in subjs for tok in _get_conjunctsn(subj))\n",
    "        return subjs\n",
    "\n",
    "    def get_main_nouns_of_sent(doc):\n",
    "        \"\"\"Return the main nouns in a sentence.\"\"\"\n",
    "        return [tok for tok in doc\n",
    "                if tok.pos == NOUN ]\n",
    "\n",
    "    def getstringlist(listspacy):\n",
    "        \"\"\" Return list with list elements converted from spacy tokens to strings \"\"\"\n",
    "        liststring = []\n",
    "        for x in listspacy:\n",
    "            liststring.append(x.string)\n",
    "        return liststring\n",
    "\n",
    "    def rep_nouns_verbs_with_np_vp(nvlist,npvplist):  \n",
    "        \"\"\" Returns a list with noun phrases from given nouns in a given sentence \"\"\"\n",
    "        npvpslist = []\n",
    "        for sub in nvlist:\n",
    "                x = [s for s in npvplist if sub in s]\n",
    "                npvpslist.append(x)\n",
    "        return npvpslist\n",
    "\n",
    "\n",
    "    # def _get_prepositions(tok):\n",
    "    #     \"\"\" Return prepositions of the token listed in a doc \"\"\"\n",
    "    #     return [right for right in tok.rights\n",
    "    #             if right.dep_ in ['prep','agent','acomp','xcomp']]\n",
    "\n",
    "\n",
    "    def _get_prepositions(tok):\n",
    "        \"\"\" Return prepositions of the token listed in a doc \"\"\"\n",
    "        preps = [right for right in tok.rights\n",
    "                    if right.dep_ in ['prep','agent','acomp','xcomp']]\n",
    "        preps.extend(left for left in tok.lefts\n",
    "                                 if left.dep_ in ['prep'])\n",
    "        return preps\n",
    "\n",
    "    def getprepobjects(tok):\n",
    "        objs = [right for right in tok.rights\n",
    "                if right.dep_ == 'pobj']\n",
    "        # get open clausal complements (xcomp)\n",
    "        objs.extend(tok for tok in tok.rights\n",
    "                    if tok.dep_ == 'xcomp')\n",
    "        objs.extend(tok for obj in objs for tok in _get_conjunctsv(obj))\n",
    "        return objs\n",
    "\n",
    "    def prepositionslist(nounverblist):\n",
    "        nprep = []\n",
    "        for n1 in nounverblist:\n",
    "            cj = _get_prepositions(n1)\n",
    "            nprep.append(cj)\n",
    "        return nprep\n",
    "\n",
    "    def get_conj_list_verbnoun(nvlist):\n",
    "        conjlist = []\n",
    "        for n1 in nvlist:\n",
    "            i = 0\n",
    "            cj = _get_conjunctsn(n1)    \n",
    "            if i == 0: \n",
    "                i = 1\n",
    "               #conjlist.append(n1)\n",
    "                conjlist.append(cj)\n",
    "            else:\n",
    "                conjlist.append(cj)\n",
    "        return conjlist         \n",
    "\n",
    "    \"\"\"\n",
    "    xall contains all conjunctions of verbs in a given sentence\n",
    "    this function will return all the conjunctions that were linked to any  given verb\n",
    "    \"\"\"\n",
    "    def getverbconj(y,xall):\n",
    "        xs = []\n",
    "        for xindex in xall:\n",
    "            if y in xindex:\n",
    "                xs.append(xindex)\n",
    "        xs = flatten(xs)\n",
    "        xs = list(set(xs))\n",
    "        return xs\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    yall contains all the objects linked to given prepositions\n",
    "    xall contains all conjunctions list\n",
    "    this function will return all the conjunctions that were linked to any noun/verb\n",
    "    \"\"\"\n",
    "    def getobjconj(yall,xall):\n",
    "        xs = []\n",
    "        for y in yall:\n",
    "            for x in xall:\n",
    "                if y in x:\n",
    "                    xs.append(x)\n",
    "        xs = flatten(xs)\n",
    "        xs = list(set(xs))\n",
    "        return xs\n",
    "\n",
    "    \"\"\"\n",
    "    yall contains all the objects linked to given prepositions\n",
    "    xall contains all conjunctions list\n",
    "    this function will return all the conjunctions that were linked to any noun/verb\n",
    "    \"\"\"\n",
    "    def getobjconjtest(yone,xall):\n",
    "        xs = []\n",
    "        #for y in yall:\n",
    "        for x in xall:\n",
    "                if yone in x:\n",
    "                    xs.append(x)\n",
    "        xs = flatten(xs)\n",
    "        xs = list(set(xs))\n",
    "\n",
    "        return xs\n",
    "\n",
    "    def mergeverbconj(l):\n",
    "\n",
    "        \"\"\"\n",
    "            Algorithm Logic:\n",
    "            1. take first set A from list\n",
    "            2. for each other set B in the list do if B has common element(s) with A join B into A; remove B from list\n",
    "            3. repeat 2. until no more overlap with A\n",
    "            4. put A into outpup\n",
    "            5. repeat 1. with rest of list \n",
    "        \"\"\"\n",
    "\n",
    "        out = []\n",
    "        while len(l)>0:\n",
    "            first, *rest = l\n",
    "            first = set(first)\n",
    "\n",
    "            lf = -1\n",
    "            while len(first)>lf:\n",
    "                lf = len(first)\n",
    "\n",
    "                rest2 = []\n",
    "                for r in rest:\n",
    "                    if len(first.intersection(set(r)))>0:\n",
    "                        first |= set(r)\n",
    "                    else:\n",
    "                        rest2.append(r)     \n",
    "                rest = rest2\n",
    "\n",
    "            out.append(first)\n",
    "            l = rest\n",
    "\n",
    "        return out\n",
    "\n",
    "    def get_all_noun_conjunctions(doc):\n",
    "        \"\"\"\n",
    "            Algorithm Logic\n",
    "                1. Get all nouns from the given sentence outputs a list\n",
    "                2. for every noun get the conjunctions linked to it this ouputs a list\n",
    "                3. zip two list to get conjunctions associated to each noun in a list\n",
    "                4. flatten the tuple elements for every element in the zipped list\n",
    "                5. merge nounconjunctions which were linked to each other in the set\n",
    "        \"\"\"\n",
    "        nouns = get_main_nouns_of_sent(doc)\n",
    "        nounconj = get_conj_list_verbnoun(nouns)\n",
    "        nounconj =list(zip(nouns,nounconj))\n",
    "        nounconjf = []\n",
    "        nounconjf =[(a, *rest) for a, rest in nounconj]\n",
    "        nounconjs = mergeverbconj(nounconjf)\n",
    "        nounconjll = []\n",
    "        for x in nounconjs:\n",
    "             nounconjll.append(list(x))\n",
    "        return nounconjll\n",
    "\n",
    "    def get_all_verb_conjunctions(doc):\n",
    "        \"\"\"\n",
    "        Algorithm Logic\n",
    "        1. Get all verbs from the given sentence outputs a list\n",
    "        2. for every verb get the conjunctions linked to it this ouputs a list\n",
    "        3. zip two list to get conjunctions associated to each verb\n",
    "        4. flatten the tuple elements for every element in the zipped list\n",
    "        5. merge verbconjunctions which were linked to each other in the set\n",
    "        \"\"\"\n",
    "        verbs =[]\n",
    "        verbs = spacy_utils.get_main_verbs_of_sent(doc)\n",
    "        verbconj = []\n",
    "        verbconj = get_conj_list_verbnoun(verbs)\n",
    "        verbconjl = []\n",
    "        verbconjl =list(zip(verbs,verbconj))\n",
    "        verbconjf = []\n",
    "        verbconjf =[(a, *rest) for a, rest in verbconjl]\n",
    "        verbconjs = mergeverbconj(verbconjf)\n",
    "        verbconjll = []\n",
    "        for x in verbconjs:\n",
    "            verbconjll.append(list(x))           \n",
    "        return verbconjll\n",
    "\n",
    "    def get_objects_of_verb(verb):\n",
    "        \"\"\"\n",
    "        Return all objects of a verb according to the dependency parse,\n",
    "        including open clausal complements.\n",
    "        \"\"\"\n",
    "        objs = [tok for tok in verb.rights\n",
    "                if tok.dep_ in OBJ_DEPS1]    \n",
    "        objs.extend(tok for tok in verb.lefts\n",
    "                if tok.dep_ in OBJ_DEPS1)\n",
    "        # get open clausal complements (xcomp)\n",
    "        objs.extend(tok for tok in verb.rights\n",
    "                    if tok.dep_ == 'xcomp')\n",
    "        # get additional conjunct objects\n",
    "        objs.extend(tok for obj in objs for tok in spacy_utils._get_conjuncts(obj))\n",
    "        return objs\n",
    "\n",
    "    def get_all_verb_advcl(doc):\n",
    "        \"\"\"\n",
    "        Algorithm Logic\n",
    "        1. Get all verbs from the given sentence outputs a list\n",
    "        2. for every verb get the conjunctions linked to it this ouputs a list\n",
    "        3. zip two list to get conjunctions associated to each verb\n",
    "        4. flatten the tuple elements for every element in the zipped list\n",
    "        5. merge verbconjunctions which were linked to each other in the set\n",
    "        \"\"\"\n",
    "        verbs =[]\n",
    "        verbs = spacy_utils.get_main_verbs_of_sent(doc)\n",
    "        advclverbs = []\n",
    "        for verb in verbs:\n",
    "            advclverbs.append([tok for tok in verb.rights\n",
    "                                    if tok.dep_  in ['advcl']])\n",
    "        verbconjl = []\n",
    "        verbconjl =list(zip(verbs,advclverbs))\n",
    "        verbconjf = []\n",
    "        verbconjf =[(a, *rest) for a, rest in verbconjl]\n",
    "        #verbconjs = mergeverbconj(verbconjf)\n",
    "        verbconjll = []\n",
    "        for x in verbconjf:\n",
    "             verbconjll.append(list(x))\n",
    "        return verbconjll\n",
    "\n",
    "    def get_all_verb_acl(doc):\n",
    "        nouns = get_main_nouns_of_sent(doc)\n",
    "        acllist = []\n",
    "        for noun in nouns:\n",
    "            acllist.append([tok for tok in noun.rights\n",
    "                        if tok.dep_  in ['acl']])\n",
    "        verbconjl = []\n",
    "        verbconjl =list(zip(nouns,acllist))\n",
    "        verbconjf = []\n",
    "        verbconjf =[(a, *rest) for a, rest in verbconjl]\n",
    "        verbconjll = []\n",
    "        for x in verbconjf:\n",
    "            verbconjll.append(list(x))\n",
    "        return verbconjll\n",
    "\n",
    "\n",
    "    def get_all_verb_xcomp(doc):\n",
    "        \"\"\"\n",
    "        Algorithm Logic\n",
    "        1. Get all verbs from the given sentence outputs a list\n",
    "        2. for every verb get the xcomp linked to it this ouputs a list\n",
    "        3. zip two list to get xcomp associated to each verb\n",
    "        4. flatten the tuple elements for every element in the zipped list\n",
    "        5. merge verbconjunctions which were linked to each other in the set\n",
    "        \"\"\"\n",
    "        verbs =[]\n",
    "        verbs = spacy_utils.get_main_verbs_of_sent(doc)\n",
    "        xcompverbs = []\n",
    "        for verb in verbs:\n",
    "            xcompverbs.append([tok for tok in verb.rights\n",
    "                                    if tok.dep_  in ['xcomp']])\n",
    "        verbconjl = []\n",
    "        verbconjl =list(zip(verbs,xcompverbs))\n",
    "        verbconjf = []\n",
    "        verbconjf =[(a, *rest) for a, rest in verbconjl]\n",
    "        #verbconjs = mergeverbconj(verbconjf)\n",
    "        verbconjll = []\n",
    "        for x in verbconjf:\n",
    "             verbconjll.append(list(x))\n",
    "        return verbconjll\n",
    "\n",
    "    def getsubjects_ofthe_verb(verb,sent):\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            acllist   = get_all_verb_acl(sent)\n",
    "            advclverbs= get_all_verb_advcl(sent)\n",
    "            xcompverbs= get_all_verb_xcomp(sent)\n",
    "            subjsa = get_subjects_of_sent(sent)\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "\n",
    "            subjs = spacy_utils.get_subjects_of_verb(verb) \n",
    "            verbsy = []\n",
    "\n",
    "            # if direct subjects doesn't exist for verb , get subject from conjunction verbs to it\n",
    "            conjverb = getobjconjtest(verb,verbconjl)\n",
    "            conjnoun = getobjconjtest(verb,nounconjl)\n",
    "            if len(conjverb) > 0:\n",
    "                verbsy.extend(conjverb)\n",
    "            if len(conjnoun) > 0:\n",
    "                verbsy.extend(conjnoun)\n",
    "\n",
    "            if len(subjs) == 0:\n",
    "                for cverbs in verbsy:\n",
    "                    subjs.extend(spacy_utils.get_subjects_of_verb(cverbs))\n",
    "\n",
    "            # check for open clausal compliment exist (xcomp) for verb\n",
    "            if len(subjs) == 0:\n",
    "                xcompx = getobjconjtest(verb,xcompverbs)\n",
    "                if len(xcompx) > 1:\n",
    "                    for xcompxx in xcompx:\n",
    "                        subjs.extend(spacy_utils.get_subjects_of_verb(xcompxx))\n",
    "\n",
    "            # if direct subjects and conjunctional subjects doesn't exist for verb , get subject from adverbial clauses\n",
    "            if len(subjs) == 0:\n",
    "                advclx = getobjconjtest(verb,advclverbs)\n",
    "                if len(advclx) > 1:\n",
    "                    for advclxx in advclx:\n",
    "                        subjs.extend(spacy_utils.get_subjects_of_verb(advclxx))\n",
    "\n",
    "            # if direct subjects, conjunctional verb subjects, adverbial clause subjects doesn't exist then check any acl nouns\n",
    "            if len(subjs) == 0:\n",
    "                aclx = getobjconjtest(verb,acllist)\n",
    "                if len(aclx) > 1:\n",
    "                    subjsx = []\n",
    "                    subjsx.extend([x for x in aclx if x != verb])\n",
    "                    if len(subjsx) > 0:                   \n",
    "                        subjsy = []\n",
    "                        for x in subjsx:\n",
    "                            subjsy.extend(getobjconjtest(x,nounconjl))\n",
    "                        if len(subjsy) > 0:\n",
    "                            subjs.extend(subjsy)\n",
    "                    if len(subjs) == 0:\n",
    "                        subjs.extend(subjsx)\n",
    "\n",
    "            # if no subject exist get the default first subject of the sentence  \n",
    "            if len(subjs) == 0:\n",
    "                if len(subjsa) > 0:\n",
    "                    subjs.append(subjsa[0])  \n",
    "                    subjs.extend(getobjconjtest(subjsa[0],nounconjl))\n",
    "\n",
    "            subjs11 = []\n",
    "            subjsall = []\n",
    "            # replace subjects with prepositions and its objects \n",
    "            for subjs1 in subjs:\n",
    "                preps = _get_prepositions(subjs1)\n",
    "                if len(preps) > 0: \n",
    "                    for preps1 in preps:\n",
    "                        objspo = getprepobjects(preps1)\n",
    "                        if len(objspo) > 0:\n",
    "                            for objspo1 in objspo:\n",
    "                                subjs11 = getobjconjtest(objspo1,nounconjl)\n",
    "                                if len(subjs11) > 0:\n",
    "                                    for subjs111 in subjs11:\n",
    "                                        subjs1x = replaceobj_withcompoundobj(subjs1,sent)\n",
    "                                        subjs111x = replaceobj_withcompoundobj(subjs111,sent)\n",
    "                                        subjsall.extend([subjs1x.string + preps1.string + subjs111x.string])\n",
    "                else:\n",
    "                    subjs1x = replaceobj_withcompoundobj(subjs1,sent)\n",
    "                    subjsall.extend([subjs1x.string])\n",
    "\n",
    "            subjs = subjsall\n",
    "\n",
    "            return subjs\n",
    "\n",
    "\n",
    "    def replace_objs_with_compound_objs(objs,sent):\n",
    "        start_i = sent[0].i\n",
    "\n",
    "        objs1 = []\n",
    "        while len(objs1) > 0: objs1.pop()\n",
    "        for obj in objs:\n",
    "                if obj.pos == NOUN:\n",
    "                    span = get_span_for_compound_noun(obj)\n",
    "                elif obj.pos == VERB:\n",
    "                    span = get_span_for_verb_auxiliaries(obj)\n",
    "                else:\n",
    "                    span = (obj.i, obj.i)\n",
    "                obj = sent[span[0] - start_i: span[1] - start_i + 1]\n",
    "\n",
    "                objs1.append(obj)\n",
    "        return objs1\n",
    "\n",
    "\n",
    "    # def replace_verbs_with_auxillary_verbs(verbs,sent):\n",
    "    #     start_i = sent[0].i\n",
    "\n",
    "    #     verbsl = []\n",
    "    #     while len(verbsl) > 0: verbsl.pop()\n",
    "    #     for verb in verbs:\n",
    "    #         verb_span = get_span_for_verb_auxiliaries(verb)\n",
    "    #         verb = sent[verb_span[0] - start_i: verb_span[1] - start_i + 1]\n",
    "\n",
    "    #         verbsl.append(verb)\n",
    "    #     return verbsl\n",
    "\n",
    "    def replace_verbs_with_auxillary_verbs(verb,verbs,sent):\n",
    "        start_i = sent[0].i\n",
    "\n",
    "        verbs.remove(verb)\n",
    "        verbsl = []\n",
    "        while len(verbsl) > 0: verbsl.pop()\n",
    "\n",
    "        if len(verbs) > 0:\n",
    "            for verb in verbs:\n",
    "                verb_span = get_span_for_verb_auxiliaries(verb)\n",
    "                verbq = sent[verb_span[0] - start_i: verb_span[1] - start_i + 1]\n",
    "\n",
    "                verbsl.append(verbq.string)\n",
    "\n",
    "        xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "        if len(xcompverb) > 0: \n",
    "            verbx = xcompverb[0]\n",
    "            verbsl.insert(0,verbx)\n",
    "        else:\n",
    "            verb_span = get_span_for_verb_auxiliaries(verb)\n",
    "            verbq = sent[verb_span[0] - start_i: verb_span[1] - start_i + 1]\n",
    "            verbsl.insert(0,verbq.string)\n",
    "\n",
    "        return verbsl\n",
    "\n",
    "    def getxcomp_ofthe_verb(verb,sent):\n",
    "        start_i = sent[0].i\n",
    "        xcompxx=[]\n",
    "        xcompy = []\n",
    "        xcompverbs= get_all_verb_xcomp(sent)\n",
    "        xcompx = getobjconjtest(verb,xcompverbs)\n",
    "        xcompy = [x for x in xcompx if x != verb]\n",
    "        m1 = [tok for tok in verb.rights\n",
    "                            if tok.dep_  in ['xcomp']]\n",
    "        if len(m1) == 0 and len(xcompy) > 0:\n",
    "            verbxt = replaceverb_withauxillaryverb(xcompy[0],sent)\n",
    "            verbx  = replaceverb_withauxillaryverb(verb,sent)\n",
    "            verbx = verbxt + verbx\n",
    "            xcompxx.insert(0,verbx)\n",
    "\n",
    "        return xcompxx\n",
    "\n",
    "    def replaceverb_withauxillaryverb(verb,sent):\n",
    "        start_i = sent[0].i\n",
    "\n",
    "        verb_span = get_span_for_verb_auxiliaries(verb)\n",
    "        verb = sent[verb_span[0] - start_i: verb_span[1] - start_i + 1]\n",
    "        return verb.string\n",
    "\n",
    "    def replaceobj_withcompoundobj(obj,sent):\n",
    "        start_i = sent[0].i\n",
    "\n",
    "        if obj.pos == NOUN:\n",
    "            span = get_span_for_compound_noun(obj)\n",
    "        elif obj.pos == VERB:\n",
    "            span = get_span_for_verb_auxiliaries(obj)\n",
    "        else:\n",
    "            span = (obj.i, obj.i)\n",
    "        obj = sent[span[0] - start_i: span[1] - start_i + 1]\n",
    "\n",
    "\n",
    "        return obj  \n",
    "\n",
    "    def verbswithdobjs(verb,cverbsy,sent):\n",
    "\n",
    "        verbswithdobj = []\n",
    "        verbs2 = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "        for verb21 in verbs2:\n",
    "            objs =  get_objects_of_verb(verb21)\n",
    "            if len(objs) > 0:\n",
    "                verbswithdobj.insert(0,verb21)\n",
    "\n",
    "\n",
    "        v1 = [x for x in cverbsy if x != verb]\n",
    "        for v11 in v1:\n",
    "            if v11 in verbswithdobj:\n",
    "                v1.remove(v11)\n",
    "        v1.insert(0,verb)\n",
    "        return v1\n",
    "\n",
    "\n",
    "    # verb---object---prep1---pobj1/pobj11/pobj12\n",
    "    #        or    ---prep2---pobj2/pobj21/pobj22\n",
    "    #        (acomp)\n",
    "\n",
    "    # verb---object---prep1---pobj1---prep2---pobj21/pobj22\n",
    "    #        or    ---prep3---pobj3---prep4---pobj41/pobj42\n",
    "    #        (acomp)\n",
    "\n",
    "    def subject_verb_object_pattern1(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            acllist   = get_all_verb_acl(sent)\n",
    "            advclverbs= get_all_verb_advcl(sent)\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objs = spacy_utils.get_objects_of_verb(verb)\n",
    "\n",
    "                objacomp = [tok for tok in verb.rights\n",
    "                                    if tok.dep_  in ['acomp']]     # check if any acomp objects exist for verb\n",
    "                if len(objacomp) > 0:\n",
    "                    objs.extend(objacomp) \n",
    "\n",
    "                objsc = getobjconj(objs,nounconjl)                     # get all object conjunctions to object list\n",
    "                if len(objsc) > 1:\n",
    "                    objs.extend(objsc)                                     # add conjunctions to object list\n",
    "\n",
    "\n",
    "                # Check if verb objects are having any prepositions and prepositional objects and its conjunctions\n",
    "                objsy = []\n",
    "                verbsy = []\n",
    "                objspo = []\n",
    "                objs9 = []\n",
    "                cverbsy = []\n",
    "                verbstemp = []\n",
    "\n",
    "                for objsc1 in objs:\n",
    "                    preps = _get_prepositions(objsc1)                    # check for any prepositions exist for that object\n",
    "                    if len(preps) > 0:                                 # check atleast one preposition found\n",
    "                        for prepsx in preps:\n",
    "                            while len(objspo)>0 : objspo.pop()\n",
    "                            objspo = getprepobjects(prepsx)                # get pcomp object exists for preposition\n",
    "                            if len(objspo) > 0:                              # check for atleast one prepositional object found\n",
    "                                for objspox in objspo:\n",
    "                                    preps1 = _get_prepositions(objspox)\n",
    "                                    if len(preps1) == 0:                                 # check atleast one preposition found\n",
    "                                        while len(objs9) > 0 : objs9.pop()\n",
    "                                        objs9.extend(objspo)\n",
    "                                        objs1 = getobjconjtest(objspox,nounconjl) \n",
    "                                        if len(objs1) > 1:   \n",
    "                                            objs9.extend(objs1)\n",
    "                                            objs9 = list(set(objs9))\n",
    "\n",
    "                                        objs9 = replace_objs_with_compound_objs(objs9,sent)\n",
    "                                        \"\"\"Replacing verbs with conjunction verbs\n",
    "                                        \"\"\" \n",
    "                                        while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                        while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                        conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                        conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                        if len(conjverb) > 0:\n",
    "                                            cverbsy.extend(conjverb)\n",
    "                                        if len(conjnoun) > 0:\n",
    "                                            cverbsy.extend(conjnoun)\n",
    "                                        cverbsy = verbswithdobjs(verb,cverbsy,sent)  # remove conjunction verbs if they have direct objects exists\n",
    "\n",
    "                                        cverbsy = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                        objsc1conj = getobjconjtest(objsc1,nounconjl)\n",
    "\n",
    "                                        objsc1conj = replace_objs_with_compound_objs(objsc1conj,sent)\n",
    "                                        objsc1x = replaceobj_withcompoundobj(objsc1,sent)\n",
    "                                        verbx = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                        if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "\n",
    "\n",
    "                                        if len(cverbsy) > 1:\n",
    "                                            if len(objsc1conj) > 1:\n",
    "                                                for cverbsy1 in cverbsy:\n",
    "                                                    for objsc1conj1 in objsc1conj:\n",
    "                                                        verbstemp.extend([cverbsy1 + objsc1conj1.string + prepsx.string])\n",
    "                                            else:\n",
    "                                                for cverbsy1 in cverbsy:\n",
    "                                                    verbstemp.extend([cverbsy1 + objsc1x.string + prepsx.string])\n",
    "                                        else:\n",
    "                                            if len(objsc1conj) > 1:\n",
    "                                                for objsc1conj1 in objsc1conj:\n",
    "                                                    verbstemp.extend([verbx + objsc1conj1.string + prepsx.string])\n",
    "                                            else:\n",
    "                                                verbstemp = [verbx + objsc1x.string + prepsx.string]\n",
    "\n",
    "                                        verbsy = verbstemp\n",
    "                                        \"\"\"Print triplets with extracted subjects, verbs and objects\n",
    "                                        \"\"\"\n",
    "                                        if (len(subjs) > 0) and (len(objs9)) > 0  and (len(verbsy) > 0):\n",
    "                                            for verb1 in verbsy:\n",
    "                                                for subj in subjs:\n",
    "                                                    for obj in objs9:\n",
    "                                                        yield (subj, verb1, obj)\n",
    "                                    else: \n",
    "                                        for prepsx1 in preps1:\n",
    "                                            objspo1 = getprepobjects(prepsx1)                # get pcomp object exists for preposition\n",
    "                                            if len(objspo1) > 0:                              # check for atleast one prepositional object found\n",
    "                                                for objspox1 in objspo1:\n",
    "                                                    objs9 = objspo1\n",
    "                                                    objs11 = getobjconjtest(objspox1,nounconjl)          # get all conjunctions to given nounlist \n",
    "                                                    if len(objs11) > 1:                         # if any conjunctions found for the object\n",
    "                                                        objs9.extend(objs11)\n",
    "                                                        objs9 = list(set(objs9))\n",
    "                                                        objspo1 = list(set(objspo1))\n",
    "                                                    objs9 = list(set(objs9))\n",
    "                                                    objs9 = replace_objs_with_compound_objs(objs9,sent)\n",
    "\n",
    "                                                    while len(objs11) > 0 : objs11.pop()\n",
    "\n",
    "                                                    \"\"\"Replacing verbs with conjunction verbs\n",
    "                                                    \"\"\"\n",
    "                                                    while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                                    while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                                    conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                                    conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                                    if len(conjverb) > 0:\n",
    "                                                        cverbsy.extend(conjverb)\n",
    "                                                    if len(conjnoun) > 0:\n",
    "                                                        cverbsy.extend(conjnoun)\n",
    "\n",
    "                                                    cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                                    cverbsy = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                                    objsc1x = replaceobj_withcompoundobj(objsc1,sent)\n",
    "                                                    objspoxx = replaceobj_withcompoundobj(objspox,sent)\n",
    "                                                    verbx = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                                    if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "\n",
    "                                                    if len(cverbsy) > 1:\n",
    "                                                        for cverbsy1 in cverbsy:\n",
    "                                                            verbstemp.extend([cverbsy1 + objsc1x.string + prepsx.string + objspoxx.string + prepsx1.string])\n",
    "                                                    else:\n",
    "                                                            verbstemp = [verbx + objsc1x.string + prepsx.string + objspoxx.string + prepsx1.string]\n",
    "\n",
    "                                                    verbsy = verbstemp\n",
    "\n",
    "\n",
    "                                                    #verbstemp = [verb.string + objsc1.string + prepsx.string + objspox.string + prepsx1.string]\n",
    "                                                    #verbsy = verbstemp\n",
    "                                                    \"\"\"Print triplets with extracted subjects, verbs and objects\n",
    "                                                    \"\"\"\n",
    "                                                    if (len(subjs) > 0) and (len(objs9)) > 0  and (len(verbsy) > 0):\n",
    "                                                        for verb1 in verbsy:\n",
    "                                                            for subj in subjs:\n",
    "                                                                for obj1 in objs9:\n",
    "                                                                    yield (subj, verb1, obj1)                                    \n",
    "                                                while len(objspo1) > 0: objspo1.pop()\n",
    "                                        while len(preps1) > 0 : preps1.pop()\n",
    "                                while len(objspo) > 0 : objspo.pop()\n",
    "                        while len(preps)>0 : preps.pop()\n",
    "\n",
    "    # verbs---prep1---pobj1/pobj11/pobj12\n",
    "    #      ---prep2---pobj2/pobj21/pobj22\n",
    "\n",
    "    #verbs---prep1---pobj1---prep2---pobj21/pobj22\n",
    "    #                     ---prep3---pobj31/pobj32\n",
    "\n",
    "    def subject_verb_object_pattern2(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objs = []\n",
    "                objs = spacy_utils.get_objects_of_verb(verb)\n",
    "                objsy = []\n",
    "                objsy1 = []\n",
    "                verbsy = []\n",
    "                objspo = []\n",
    "                objs9 = []    \n",
    "                verbstemp = []\n",
    "                cverbsy = []\n",
    "                # check if verb is having prepositions and prepositional objects and its conjunctions                \n",
    "\n",
    "                preps = _get_prepositions(verb)                    # check for any prepositions exist for that object\n",
    "                if len(preps) > 0 and len(objs) == 0 :                                 # check atleast one preposition found\n",
    "                    for prepsx in preps:\n",
    "                        while len(objspo) > 0: objspo.pop() \n",
    "                        objspo = getprepobjects(prepsx)                # get pcomp object exists for preposition\n",
    "                        if len(objspo) > 0:                              # check for atleast one prepositional object found\n",
    "                            for objspox in objspo:\n",
    "                                preps1 = _get_prepositions(objspox)\n",
    "                                if len(preps1) == 0:                                 # check atleast one preposition found\n",
    "                                    while len(objsy) > 0: objsy.pop()\n",
    "                                    objsy.extend(objspo)\n",
    "                                    objs1 = getobjconjtest(objspox,nounconjl) \n",
    "                                    if len(objs1) > 1:   \n",
    "                                        objsy.extend(objs1)  \n",
    "                                        objsy = list(set(objsy))\n",
    "                                    objsy = replace_objs_with_compound_objs(objsy,sent)\n",
    "                                    \"\"\" Replace verbs with conjunction verbs\n",
    "                                    \"\"\"\n",
    "                                    while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                    while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                    conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                    conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                    if len(conjverb) > 0:\n",
    "                                        cverbsy.extend(conjverb)\n",
    "                                    if len(conjnoun) > 0:\n",
    "                                        cverbsy.extend(conjnoun)\n",
    "\n",
    "                                    cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                    cverbsy = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                    verbx = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                    if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "\n",
    "                                    if len(cverbsy) > 1:\n",
    "                                        for cverbsy1 in cverbsy:\n",
    "                                            verbstemp.extend([cverbsy1 + prepsx.string])\n",
    "                                    else:\n",
    "                                        verbstemp = [verbx + prepsx.string]\n",
    "                                    verbsy = verbstemp        \n",
    "                                    #verbstemp = [verb.string + prepsx.string]\n",
    "                                    #verbsy = verbstemp \n",
    "                                    if (len(subjs) > 0) and (len(objsy)) > 0  and (len(verbsy) > 0):\n",
    "                                        for verb1 in verbsy:\n",
    "                                            for subj in subjs:\n",
    "                                                for obj in objsy:\n",
    "                                                    yield (subj, verb1, obj)\n",
    "\n",
    "                                else:    \n",
    "\n",
    "                                    for prepsx1 in preps1:\n",
    "                                        objspo1 = getprepobjects(prepsx1)                # get pcomp object exists for preposition\n",
    "                                        if len(objspo1) > 0:                              # check for atleast one prepositional object found\n",
    "                                            for objspox1 in objspo1:\n",
    "                                                while len(objsy1) > 0: objsy1.pop()\n",
    "                                                objsy1.extend(objspo1)\n",
    "                                                objs11 = getobjconjtest(objspox1,nounconjl)          # get all conjunctions to given nounlist \n",
    "                                                if len(objs11) > 1:                         # if any conjunctions found for the object\n",
    "                                                    objsy1.extend(objs11)                           # replace retrieved objects to objs list \n",
    "                                                    objsy1 = list(set(objsy))\n",
    "                                                objsy1 = replace_objs_with_compound_objs(objsy1,sent)\n",
    "\n",
    "                                                \"\"\" Replace verbs with conjunction verbs\n",
    "                                                \"\"\"\n",
    "                                                while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                                while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                                conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                                conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                                if len(conjverb) > 0:\n",
    "                                                    cverbsy.extend(conjverb)\n",
    "                                                if len(conjnoun) > 0:\n",
    "                                                    cverbsy.extend(conjnoun)\n",
    "                                                cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                                cverbsy = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                                objspoxx = replaceobj_withcompoundobj(objspox,sent)\n",
    "                                                verbx    = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                                if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "\n",
    "                                                if len(cverbsy) > 1:\n",
    "                                                    for cverbsy1 in cverbsy:\n",
    "                                                        verbstemp.extend([cverbsy1 + prepsx.string + objspoxx.string + prepsx1.string])\n",
    "                                                else:\n",
    "                                                    verbstemp = [verbx + prepsx.string + objspoxx.string + prepsx1.string]\n",
    "                                                verbsy = verbstemp        \n",
    "\n",
    "\n",
    "\n",
    "                                                #verbstemp = [verb.string + prepsx.string + objspox.string + prepsx1.string]\n",
    "                                                #verbsy = verbstemp\n",
    "                                                if (len(subjs) > 0) and (len(objsy1)) > 0  and (len(verbsy) > 0):\n",
    "                                                    for verb1 in verbsy:\n",
    "                                                        for subj in subjs:\n",
    "                                                            for obj1 in objsy1:\n",
    "                                                                yield (subj, verb1, obj1)   \n",
    "                                            while len(objspo1) > 0: objspo1.pop()                    \n",
    "                                    while len(preps1) > 0 : preps1.pop()\n",
    "                            while len(objspo) > 0 : objspo.pop()\n",
    "                    while len(preps)>0 : preps.pop()            \n",
    "\n",
    "\n",
    "    #verb---prep1(verb)---prep2---pobj11/pobj12\n",
    "\n",
    "    def subject_verb_object_pattern3(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objs = []\n",
    "                objsy = []\n",
    "                verbsy = []\n",
    "                objs11 = []\n",
    "                objspo1 = []\n",
    "                prepsx1 = []\n",
    "                preps = []\n",
    "                verbstemp = []\n",
    "                cverbsy = []\n",
    "\n",
    "                # check if verb is having multiple prepositions which are verbs, which again have prepositions and prepositional objects and its conjunctions\n",
    "                verbsy = []\n",
    "                preps = _get_prepositions(verb)                    # check for any prepositions exist for that object\n",
    "                if len(preps) > 0:                                 # check atleast one preposition found\n",
    "                    for prepsx in preps:\n",
    "                        if prepsx.pos == VERB:\n",
    "                            prepsx1 = _get_prepositions(prepsx)                    # check for any prepositions exist for that object\n",
    "                            objs    =  get_objects_of_verb(prepsx)\n",
    "                            if len(prepsx1) > 0 and len(objs) == 0:                                 # check atleast one preposition found\n",
    "                                for prepsx11 in prepsx1:\n",
    "                                    objspo1 = getprepobjects(prepsx11)    \n",
    "                                    if len(objspo1) > 0:                              # check for atleast one prepositional object found\n",
    "                                        for objspox1 in objspo1:\n",
    "                                            while len(objsy) > 0 : objsy.pop()\n",
    "                                            objsy.extend(objspo1)\n",
    "                                            objs11 = getobjconjtest(objspox1,nounconjl)          # get all conjunctions to given nounlist \n",
    "                                            if len(objs11) > 0:                         # if any conjunctions found for the object\n",
    "                                                objsy.extend(objs11)                           # replace retrieved objects to objs list \n",
    "                                                objsy = list(set(objsy))\n",
    "                                            objsy = replace_objs_with_compound_objs(objsy,sent)\n",
    "\n",
    "                                            \"\"\" Replace verbs with conjunction verbs\n",
    "                                            \"\"\"\n",
    "                                            while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                            while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                            conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                            conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                            if len(conjverb) > 0:\n",
    "                                                cverbsy.extend(conjverb)\n",
    "                                            if len(conjnoun) > 0:\n",
    "                                                cverbsy.extend(conjnoun)\n",
    "\n",
    "                                            cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                            cverbsy = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                            verbx    = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                            if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "                                            prepsxz    = replaceverb_withauxillaryverb(prepsx,sent)\n",
    "\n",
    "\n",
    "                                            if len(cverbsy) > 1:\n",
    "                                                for cverbsy1 in cverbsy:\n",
    "                                                    verbstemp.extend([cverbsy1 + prepsxz + prepsx11.string])\n",
    "                                            else:\n",
    "                                                verbstemp = [verbx + prepsxz + prepsx11.string]\n",
    "                                            verbsy = verbstemp        \n",
    "\n",
    "                                            #verbstemp = [verb.string + prepsx.string + prepsx11.string]\n",
    "                                            #verbsy = verbstemp\n",
    "\n",
    "                                            if (len(subjs) > 0) and (len(objsy)) > 0  and (len(verbsy) > 0):\n",
    "                                                for verb1 in verbsy:\n",
    "                                                    for subj in subjs:\n",
    "                                                        for obj1 in objsy:\n",
    "                                                            yield (subj, verb1, obj1)   \n",
    "\n",
    "                                        while len(objspo1) > 0 : objspo1.pop()\n",
    "                                while len(prepsx1) > 0 : prepsx1.pop()    \n",
    "                    while len(preps) > 0 : preps.pop()\n",
    "\n",
    "    #verb---prep1---pcomp(verb)---dobj11/dobj12\n",
    "\n",
    "    def subject_verb_object_pattern4(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objs = []\n",
    "                objsy = []\n",
    "                verbsy = []\n",
    "                preps = []\n",
    "                prepsx1 = []\n",
    "                objspo1 = []\n",
    "                verbstemp = []\n",
    "                cverbsy = []\n",
    "\n",
    "                # check if verb is having multiple prepositions which are having pcomp and is a verb, which again have prepositions and prepositional objects and its conjunctions\n",
    "                preps = _get_prepositions(verb)                    # check for any prepositions exist for that object\n",
    "                if len(preps) > 0:                                 # check atleast one preposition found\n",
    "                    for prepsx in preps:\n",
    "                            prepsx1 = [tok for tok in prepsx.rights\n",
    "                                            if tok.dep_  in ['pcomp']]\n",
    "                            if len(prepsx1) > 0:                                 # check atleast one preposition found\n",
    "                                for prepsx11 in prepsx1:\n",
    "                                    if prepsx11.pos == VERB:\n",
    "                                        objspo1 = spacy_utils.get_objects_of_verb(prepsx11)    \n",
    "                                        if len(objspo1) > 0:                              # check for atleast one prepositional object found\n",
    "                                            for objspox1 in objspo1:\n",
    "                                                while len(objsy) > 0 : objsy.pop()\n",
    "                                                objsy.extend(objspo1)\n",
    "                                                objs11 = getobjconjtest(objspox1,nounconjl)          # get all conjunctions to given nounlist \n",
    "                                                if len(objs11) > 0:                         # if any conjunctions found for the object\n",
    "                                                    objsy.extend(objs11)                           # replace retrieved objects to objs list \n",
    "                                                    objsy = list(set())\n",
    "                                                objsy = replace_objs_with_compound_objs(objsy,sent)\n",
    "\n",
    "                                                \"\"\" Replace verbs with conjunction verbs\n",
    "                                                \"\"\"\n",
    "                                                while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                                while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                                conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                                conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                                if len(conjverb) > 0:\n",
    "                                                    cverbsy.extend(conjverb)\n",
    "                                                if len(conjnoun) > 0:\n",
    "                                                    cverbsy.extend(conjnoun)\n",
    "\n",
    "                                                cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                                cverbsy = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                                verbx    = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                                if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "                                                prepsx11z= replaceverb_withauxillaryverb(prepsx11,sent)\n",
    "\n",
    "                                                if len(cverbsy) > 1:\n",
    "                                                    for cverbsy1 in cverbsy:\n",
    "                                                        verbstemp.extend([cverbsy1 + prepsx.string + prepsx11z])\n",
    "                                                else:\n",
    "                                                    verbstemp = [verbx + prepsx.string + prepsx11z]\n",
    "                                                verbsy = verbstemp        \n",
    "\n",
    "                                                #verbstemp = [verb.string + prepsx.string + prepsx11.string]\n",
    "                                                #verbsy = verbstemp\n",
    "\n",
    "                                                if (len(subjs) > 0) and (len(objsy)) > 0  and (len(verbsy) > 0):\n",
    "                                                    for verb1 in verbsy:\n",
    "                                                        for subj in subjs:\n",
    "                                                            for obj1 in objsy:\n",
    "                                                                yield (subj, verb1, obj1)   \n",
    "\n",
    "                                            while len(objspo1) > 0 : objspo1.pop()\n",
    "                                while len(prepsx1) > 0 : prepsx1.pop()    \n",
    "                    while len(preps) > 0 : preps.pop()        \n",
    "\n",
    "\n",
    "\n",
    "    #verb---attr---prep1---pobj11/pobj12\n",
    "\n",
    "    def subject_verb_object_pattern5(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objs = []\n",
    "                objsy = []\n",
    "                verbsy = []\n",
    "                attrx = []\n",
    "                preps = []\n",
    "                objspo = [] \n",
    "                verbstemp = []  \n",
    "                cverbsy = []\n",
    "                # check if verb is having attribute followed by preposition and with preposition objects\n",
    "                attrx = [tok for tok in verb.rights\n",
    "                            if tok.dep_  in ['attr']]\n",
    "                if len(attrx) > 0:                                 # check atleast one preposition found\n",
    "                    for attrx1 in attrx:\n",
    "\n",
    "                            preps = _get_prepositions(attrx1)       \n",
    "                            if len(preps) > 0:                                 # check atleast one preposition found\n",
    "                                for prepsx in preps:\n",
    "                                        objspo = getprepobjects(prepsx) \n",
    "                                        if len(objspo) > 0:                              # check for atleast one prepositional object found\n",
    "                                            for objspo1 in objspo:\n",
    "                                                while len(objsy) > 0 : objsy.pop()\n",
    "                                                objsy.extend(objspo)\n",
    "                                                objs11 = getobjconjtest(objspo1,nounconjl)          # get all conjunctions to given nounlist \n",
    "                                                if len(objs11) > 0:                         # if any conjunctions found for the object\n",
    "                                                    objsy.extend(objs11)                           # replace retrieved objects to objs list \n",
    "                                                    objsy = list(set(objsy))\n",
    "                                                objsy = replace_objs_with_compound_objs(objsy,sent)\n",
    "\n",
    "                                                \"\"\" Replace verbs with conjunction verbs\n",
    "                                                \"\"\"\n",
    "                                                while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                                while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                                conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                                conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                                if len(conjverb) > 0:\n",
    "                                                    cverbsy.extend(conjverb)\n",
    "                                                if len(conjnoun) > 0:\n",
    "                                                    cverbsy.extend(conjnoun)\n",
    "\n",
    "                                                cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                                cverbsy = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                                attrx1z  = replaceobj_withcompoundobj(attrx1,sent)\n",
    "                                                verbx    = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                                if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "\n",
    "                                                if len(cverbsy) > 1:\n",
    "                                                    for cverbsy1 in cverbsy:\n",
    "                                                        verbstemp.extend([cverbsy1 + attrx1z.string + prepsx.string])\n",
    "                                                else:\n",
    "                                                    verbstemp = [verbx + attrx1z.string + prepsx.string]\n",
    "                                                verbsy = verbstemp        \n",
    "\n",
    "                                                #verbstemp = [verb.string + attrx1.string + prepsx.string]\n",
    "                                                #verbsy = verbstemp          \n",
    "                                                if (len(subjs) > 0) and (len(objsy)) > 0  and (len(verbsy) > 0):\n",
    "                                                    for verb1 in verbsy:\n",
    "                                                        for subj in subjs:\n",
    "                                                            for obj1 in objsy:\n",
    "                                                                yield (subj, verb1, obj1)   \n",
    "\n",
    "                                            while len(objspo) > 0 : objspo.pop()\n",
    "                                while len(preps) > 0 : preps.pop()    \n",
    "                    while len(attrx) > 0 : attrx.pop()                             \n",
    "\n",
    "\n",
    "\n",
    "    # verb---dobj11/dobj12 or (acomp)\n",
    "\n",
    "    def subject_verb_object_pattern6(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            acllist   = get_all_verb_acl(sent)\n",
    "            advclverbs= get_all_verb_advcl(sent)\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objsy = []\n",
    "                preps = []\n",
    "                objspo= []\n",
    "                verbsy = []\n",
    "                cverbsy = []\n",
    "\n",
    "                #objs = spacy_utils.get_objects_of_verb(verb)\n",
    "                objs     = get_objects_of_verb(verb) \n",
    "                objacomp = [tok for tok in verb.rights\n",
    "                                    if tok.dep_  in ['acomp']]\n",
    "                if len(objacomp) > 0:\n",
    "                    objs.extend(objacomp)\n",
    "\n",
    "\n",
    "                # if no obects exist for the verb, get objects of conjunction verbs\n",
    "                if len(objs) == 0:\n",
    "                    conjverb = getobjconjtest(verb,verbconjl)\n",
    "\n",
    "                    if len(conjverb) > 1:   \n",
    "                        for x in conjverb:\n",
    "                            objs.extend(get_objects_of_verb(x))\n",
    "                objs = replace_objs_with_compound_objs(objs,sent)\n",
    "\n",
    "                # get  conjunction verbs \n",
    "                conjverb = getobjconjtest(verb,verbconjl)\n",
    "                conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                if len(conjverb) > 0:\n",
    "                    verbsy.extend(conjverb)\n",
    "                if len(conjnoun) > 0:\n",
    "                    verbsy.extend(conjnoun)\n",
    "                verbsy = verbswithdobjs(verb,verbsy,sent)\n",
    "\n",
    "                verbsyx = []\n",
    "                verbsy.remove(verb)\n",
    "                if len(verbsy) > 0:\n",
    "                    for verbj in verbsy:\n",
    "                        m1 = replaceverb_withauxillaryverb(verbj,sent)\n",
    "                        verbsyx.insert(0,m1)\n",
    "\n",
    "                if len(xcompverb) > 0: \n",
    "                    verbx = xcompverb[0]\n",
    "                    verbsyx.insert(0,verbx)\n",
    "                else:\n",
    "                    verbx = replaceverb_withauxillaryverb(verb,sent)\n",
    "                    verbsyx.insert(0,verbx)\n",
    "                #verbsy = replace_verbs_with_auxillary_verbs(verbsy,sent)\n",
    "\n",
    "                if (len(subjs) > 0) and (len(objs) > 0) and (len(verbsyx)>0):\n",
    "                    for verb1 in verbsyx:\n",
    "                        for subj in subjs:\n",
    "                            for obj in objs:\n",
    "                                yield (subj, verb1, obj)\n",
    "\n",
    "\n",
    "\n",
    "    #verb---dobj1\n",
    "    #    ---prep1---pobj11/pobj12---prep2---pobj21/pobj22\n",
    "\n",
    "\n",
    "    def subject_verb_object_pattern7(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "\n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objs = get_objects_of_verb(verb) \n",
    "                objacomp = [tok for tok in verb.rights\n",
    "                                    if tok.dep_  in ['acomp']]     # check if any acomp objects exist for verb\n",
    "                if len(objacomp) > 0:\n",
    "                    objs.extend(objacomp) \n",
    "\n",
    "                objsy = []\n",
    "                objsyext = []\n",
    "                preps = []\n",
    "                objspo= []\n",
    "                verbsy = []\n",
    "                cverbsy = []\n",
    "                objsy = []\n",
    "                verbsy = []\n",
    "                preps = []\n",
    "                prepsx1 = []\n",
    "                objspo1 = []\n",
    "                verbstemp = []\n",
    "                cverbsy = []\n",
    "\n",
    "\n",
    "                verbstemp = []\n",
    "                preps = _get_prepositions(verb)  \n",
    "                if len(objs) > 0 and len(preps) > 0 :\n",
    "                    for objsx in objs:\n",
    "                        if len(preps) > 0:                                 # check atleast one preposition found\n",
    "                            for prepsx in preps:\n",
    "                                objspo = getprepobjects(prepsx)    \n",
    "                                if len(objspo) > 0:                              # check for atleast one prepositional object found\n",
    "                                    for objspo1 in objspo:\n",
    "                                        while len(objsyext) > 0 : objsyext.pop()\n",
    "                                        while len(objsy) > 0 : objsy.pop()\n",
    "                                        objsy.extend(objspo)\n",
    "                                        objs11 = getobjconjtest(objspo1,nounconjl)          # get all conjunctions to given nounlist \n",
    "                                        if len(objs11) > 0:                         # if any conjunctions found for the object\n",
    "                                            objsy.extend(objs11)                           # replace retrieved objects to objs list \n",
    "                                            objsy = list(set(objsy))\n",
    "                                        \"\"\"start Check if prepositional objects is having prepositions and its objects\n",
    "                                        \"\"\"\n",
    "\n",
    "                                        for objsypr in objsy:\n",
    "                                            objsyprep = _get_prepositions(objsypr)\n",
    "                                            if len(objsyprep) > 0: \n",
    "                                                for objsyprob in objsyprep:\n",
    "                                                    objsyprobjs = getprepobjects(objsyprob)\n",
    "                                                    if len(objsyprobjs) > 0:\n",
    "                                                        for objsyprobjsy in objsyprobjs:\n",
    "                                                            objsyext.extend(objsyprobjs)\n",
    "                                                            objstt11 = getobjconjtest(objsyprobjsy,nounconjl)\n",
    "                                                            if len(objstt11) > 0:\n",
    "                                                                objsyext.extend(objstt11) \n",
    "                                                                objsyext = list(set(objstt11))\n",
    "                                        \"\"\"End Check if prepositional objects is having prepositions and its objects\n",
    "                                        \"\"\"                        \n",
    "                                        objsy = replace_objs_with_compound_objs(objsy,sent)\n",
    "                                        objsyext = replace_objs_with_compound_objs(objsyext,sent)\n",
    "\n",
    "                                        \"\"\" Replace verbs with conjunction verbs\n",
    "                                        \"\"\"\n",
    "                                        while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                        while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                        conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                        conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                        if len(conjverb) > 0:\n",
    "                                            cverbsy.extend(conjverb)\n",
    "                                        if len(conjnoun) > 0:\n",
    "                                            cverbsy.extend(conjnoun)\n",
    "\n",
    "                                        cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                        cverbsy  = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                        objsxz   = replaceobj_withcompoundobj(objsx,sent)\n",
    "                                        verbx    = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                        if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "                                        #objsyprv = replaceobj_withcompoundobj(objsypr,sent)\n",
    "\n",
    "                                        if len(cverbsy) > 1:\n",
    "                                            for cverbsy1 in cverbsy:\n",
    "                                                verbstemp.extend([cverbsy1 + objsxz.string + prepsx.string])\n",
    "                                        else:\n",
    "                                            verbstemp = [verbx + objsxz.string + prepsx.string]\n",
    "                                        verbsy = verbstemp        \n",
    "\n",
    "                                        #verbstemp = [verb.string + objsx.string + prepsx.string]\n",
    "                                        #verbsy = verbstemp          \n",
    "\n",
    "                                        if (len(subjs) > 0) and (len(objsy)) > 0  and (len(verbsy) > 0):\n",
    "                                            for verb1 in verbsy:\n",
    "                                                for subj in subjs:\n",
    "                                                    for obj1 in objsy:\n",
    "                                                        yield (subj, verb1, obj1)   \n",
    "\n",
    "                                        \"\"\"start Check if prepositional objects is having prepositions and its objects\n",
    "                                        \"\"\"                                    \n",
    "                                        if len(objsyext) > 0 and len(objsy) > 1:\n",
    "                                            if len(cverbsy) > 1:\n",
    "                                                for cverbsy1 in cverbsy:\n",
    "                                                    for objsyprv in objsy:\n",
    "                                                        verbstemp.extend([cverbsy1 + objsxz.string + prepsx.string + objsyprv.string + objsyprob.string])\n",
    "                                            else:\n",
    "                                                for objsyprv in objsy:\n",
    "                                                    verbstemp.extend([verbx + objsxz.string + prepsx.string + objsyprv.string + objsyprob.string])\n",
    "                                            verbsy = verbstemp   \n",
    "\n",
    "                                        if (len(subjs) > 0) and (len(objsyext)) > 0  and (len(verbsy) > 0):\n",
    "                                            for verb1 in verbsy:\n",
    "                                                for subj in subjs:\n",
    "                                                    for obj1 in objsyext:\n",
    "                                                        yield (subj, verb1, obj1)                                           \n",
    "                                        \"\"\"End Check if prepositional objects is having prepositions and its objects\n",
    "                                        \"\"\"                        \n",
    "\n",
    "\n",
    "                                    while len(objspo) > 0 : objspo.pop()\n",
    "                            while len(preps) > 0 : preps.pop()    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #verb---dobj1\n",
    "    #    ---prep1---pcomp(verb)---dobj21/dobj22\n",
    "\n",
    "    def subject_verb_object_pattern8(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objs = get_objects_of_verb(verb)\n",
    "                objspo= []\n",
    "                verbsy = []\n",
    "                cverbsy = []\n",
    "                verbstemp = []\n",
    "                objsy = []\n",
    "                verbsy = []\n",
    "                preps = []\n",
    "                prepsx1 = []\n",
    "                objspo1 = []\n",
    "                verbstemp = []\n",
    "                cverbsy = []\n",
    "                # check if verb is having multiple prepositions which are having pcomp and is a verb, which again have prepositions and prepositional objects and its conjunctions\n",
    "                preps = _get_prepositions(verb)                    # check for any prepositions exist for that object\n",
    "                if (len(preps) > 0) and (len(objs) > 0):                                 # check atleast one preposition found\n",
    "                    for objsx in objs:\n",
    "                        for prepsx in preps:\n",
    "                                prepsx1 = [tok for tok in prepsx.rights\n",
    "                                                if tok.dep_  in ['pcomp']]\n",
    "                                if len(prepsx1) > 0:                                 # check atleast one preposition found\n",
    "                                    for prepsx11 in prepsx1:\n",
    "                                        if prepsx11.pos == VERB:\n",
    "                                            objspo1 = spacy_utils.get_objects_of_verb(prepsx11)    \n",
    "                                            if len(objspo1) > 0:                              # check for atleast one prepositional object found\n",
    "                                                for objspox1 in objspo1:\n",
    "                                                    while len(objsy) > 0 : objsy.pop()\n",
    "                                                    objsy.extend(objspo1)\n",
    "                                                    objs11 = getobjconjtest(objspox1,nounconjl)          # get all conjunctions to given nounlist \n",
    "                                                    if len(objs11) > 0:                         # if any conjunctions found for the object\n",
    "                                                        objsy.extend(objs11)                           # replace retrieved objects to objs list \n",
    "                                                        objsy = list(set(objsy))\n",
    "                                                    objsy = replace_objs_with_compound_objs(objsy,sent)\n",
    "\n",
    "                                                    \"\"\" Replace verbs with conjunction verbs\n",
    "                                                    \"\"\"\n",
    "                                                    while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                                    while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                                    conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                                    conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                                    if len(conjverb) > 0:\n",
    "                                                        cverbsy.extend(conjverb)\n",
    "                                                    if len(conjnoun) > 0:\n",
    "                                                        cverbsy.extend(conjnoun)\n",
    "\n",
    "                                                    cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                                    cverbsy  = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                                    objsxz   = replaceobj_withcompoundobj(objsx,sent)\n",
    "                                                    prepsx11z= replaceverb_withauxillaryverb(prepsx11,sent)\n",
    "                                                    verbx    = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                                    if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "\n",
    "                                                    if len(cverbsy) > 1:\n",
    "                                                        for cverbsy1 in cverbsy:\n",
    "                                                            verbstemp.extend([cverbsy1 + objsxz.string + prepsx.string + prepsx11z])\n",
    "                                                    else:\n",
    "                                                        verbstemp = [verbx + objsxz.string + prepsx.string + prepsx11z ]\n",
    "\n",
    "                                                    verbsy = verbstemp \n",
    "\n",
    "                                                    #verbstemp = [verb.string + objsx.string + prepsx.string + prepsx11.string]\n",
    "                                                    #verbsy = verbstemp\n",
    "\n",
    "                                                    if (len(subjs) > 0) and (len(objsy)) > 0  and (len(verbsy) > 0):\n",
    "                                                        for verb1 in verbsy:\n",
    "                                                            for subj in subjs:\n",
    "                                                                for obj1 in objsy:\n",
    "                                                                    yield (subj, verb1, obj1)   \n",
    "\n",
    "                                                while len(objspo1) > 0 : objspo1.pop()\n",
    "                                    while len(prepsx1) > 0 : prepsx1.pop()    \n",
    "                        while len(preps) > 0 : preps.pop()        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #verb---dobj1\n",
    "    #    ---prep1---pcomp(verb)---prep2---pobj21/pobj22\n",
    "\n",
    "    def subject_verb_object_pattern9(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objs = get_objects_of_verb(verb)\n",
    "                objspo= []\n",
    "                verbsy = []\n",
    "                cverbsy = []\n",
    "                verbstemp = []\n",
    "                objsy = []\n",
    "                verbsy = []\n",
    "                preps = []\n",
    "                prepsx1 = []\n",
    "                objspo1 = []\n",
    "                verbstemp = []\n",
    "                cverbsy = []\n",
    "                # check if verb is having multiple prepositions which are having pcomp and is a verb, which again have prepositions and prepositional objects and its conjunctions\n",
    "                preps = _get_prepositions(verb)                    # check for any prepositions exist for that object\n",
    "                if (len(preps) > 0) and (len(objs) > 0):                                 # check atleast one preposition found\n",
    "                    for objsx in objs:\n",
    "                        for prepsx in preps:\n",
    "                                prepsx1 = [tok for tok in prepsx.rights\n",
    "                                                if tok.dep_  in ['pcomp']]\n",
    "                                if len(prepsx1) > 0:                                 # check atleast one preposition found\n",
    "                                    for prepsx11 in prepsx1:\n",
    "                                        if prepsx11.pos == VERB:\n",
    "                                            prepspo1 = _get_prepositions(prepsx11) \n",
    "                                            #objspo1 = spacy_utils.get_objects_of_verb(prepsx11)    \n",
    "                                            if len(prepspo1) > 0:                              # check for atleast one prepositional object found\n",
    "                                                for prepspo11 in prepspo1:    \n",
    "                                                    objspo1 = spacy_utils.get_objects_of_verb(prepspo11)\n",
    "                                                    if len(objspo1) > 0:\n",
    "                                                        for objspox1 in objspo1:\n",
    "                                                            while len(objsy) > 0 : objsy.pop()\n",
    "                                                            objsy.extend(objspo1)\n",
    "                                                            objs11 = getobjconjtest(objspox1,nounconjl)          # get all conjunctions to given nounlist \n",
    "                                                            if len(objs11) > 0:                         # if any conjunctions found for the object\n",
    "                                                                objsy.extend(objs11)                           # replace retrieved objects to objs list \n",
    "                                                                objsy = list(set(objsy))\n",
    "                                                            objsy = replace_objs_with_compound_objs(objsy,sent)\n",
    "\n",
    "                                                            \"\"\" Replace verbs with conjunction verbs\n",
    "                                                            \"\"\"\n",
    "                                                            while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                                            while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                                            conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                                            conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                                            if len(conjverb) > 0:\n",
    "                                                                cverbsy.extend(conjverb)\n",
    "                                                            if len(conjnoun) > 0:\n",
    "                                                                cverbsy.extend(conjnoun)\n",
    "\n",
    "                                                            cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                                            cverbsy  = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                                            objsxz   = replaceobj_withcompoundobj(objsx,sent)\n",
    "                                                            prepsx11z= replaceverb_withauxillaryverb(prepsx11,sent)\n",
    "                                                            verbx    = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                                            if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "\n",
    "                                                            if len(cverbsy) > 1:\n",
    "                                                                for cverbsy1 in cverbsy:\n",
    "                                                                    verbstemp.extend([cverbsy1 + objsxz.string + prepsx.string + prepsx11z  + prepspo11.string])\n",
    "                                                            else:\n",
    "                                                                verbstemp = [verbx + objsxz.string + prepsx.string + prepsx11z + prepspo11.string]\n",
    "\n",
    "                                                            verbsy = verbstemp \n",
    "\n",
    "                                                            #verbstemp = [verb.string + objsx.string + prepsx.string + prepsx11.string]\n",
    "                                                            #verbsy = verbstemp\n",
    "\n",
    "                                                            if (len(subjs) > 0) and (len(objsy)) > 0  and (len(verbsy) > 0):\n",
    "                                                                for verb1 in verbsy:\n",
    "                                                                    for subj in subjs:\n",
    "                                                                        for obj1 in objsy:\n",
    "                                                                            yield (subj, verb1, obj1)   \n",
    "\n",
    "                                                    while len(objspo1) > 0 : objspo1.pop()\n",
    "                                    while len(prepsx1) > 0 : prepsx1.pop()    \n",
    "                        while len(preps) > 0 : preps.pop()        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #verb---prep1---pcomp(verb)---prep2---pobj21/pobj22\n",
    "    #    \n",
    "\n",
    "    def subject_verb_object_pattern10(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objs = get_objects_of_verb(verb)\n",
    "                objspo= []\n",
    "                verbsy = []\n",
    "                cverbsy = []\n",
    "                verbstemp = []\n",
    "                objsy = []\n",
    "                verbsy = []\n",
    "                preps = []\n",
    "                prepsx1 = []\n",
    "                objspo1 = []\n",
    "                verbstemp = []\n",
    "                cverbsy = []\n",
    "                # check if verb is having multiple prepositions which are having pcomp and is a verb, which again have prepositions and prepositional objects and its conjunctions\n",
    "                preps = _get_prepositions(verb)                    # check for any prepositions exist for that object\n",
    "                if (len(preps) > 0) and (len(objs) == 0):                                 # check atleast one preposition found\n",
    "                    #for objsx in objs:\n",
    "                        for prepsx in preps:\n",
    "                                prepsx1 = [tok for tok in prepsx.rights\n",
    "                                                if tok.dep_  in ['pcomp']]\n",
    "                                if len(prepsx1) > 0:                                 # check atleast one preposition found\n",
    "                                    for prepsx11 in prepsx1:\n",
    "                                        if prepsx11.pos == VERB:\n",
    "                                            prepspo1 = _get_prepositions(prepsx11) \n",
    "                                            #objspo1 = spacy_utils.get_objects_of_verb(prepsx11)    \n",
    "                                            if len(prepspo1) > 0:                              # check for atleast one prepositional object found\n",
    "                                                for prepspo11 in prepspo1:    \n",
    "                                                    objspo1 = spacy_utils.get_objects_of_verb(prepspo11)\n",
    "                                                    if len(objspo1) > 0:\n",
    "                                                        for objspox1 in objspo1:\n",
    "                                                            while len(objsy) > 0 : objsy.pop()\n",
    "                                                            objsy.extend(objspo1)\n",
    "                                                            objs11 = getobjconjtest(objspox1,nounconjl)          # get all conjunctions to given nounlist \n",
    "                                                            if len(objs11) > 0:                         # if any conjunctions found for the object\n",
    "                                                                objsy.extend(objs11)                           # replace retrieved objects to objs list \n",
    "                                                                objsy = list(set(objsy))\n",
    "                                                            objsy = replace_objs_with_compound_objs(objsy,sent)\n",
    "\n",
    "                                                            \"\"\" Replace verbs with conjunction verbs\n",
    "                                                            \"\"\"\n",
    "                                                            while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                                            while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                                            conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                                            conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                                            if len(conjverb) > 0:\n",
    "                                                                cverbsy.extend(conjverb)\n",
    "                                                            if len(conjnoun) > 0:\n",
    "                                                                cverbsy.extend(conjnoun)\n",
    "\n",
    "                                                            cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                                            cverbsy  = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                                            objsxz   = replaceobj_withcompoundobj(objsx,sent)\n",
    "                                                            prepsx11z= replaceverb_withauxillaryverb(prepsx11,sent)\n",
    "                                                            verbx    = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                                            if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "\n",
    "                                                            if len(cverbsy) > 1:\n",
    "                                                                for cverbsy1 in cverbsy:\n",
    "                                                                    verbstemp.extend([cverbsy1 + prepsx.string + prepsx11z  + prepspo11.string])\n",
    "                                                            else:\n",
    "                                                                verbstemp = [verbx + prepsx.string + prepsx11z  + prepspo11.string]\n",
    "\n",
    "                                                            verbsy = verbstemp \n",
    "\n",
    "                                                            #verbstemp = [verb.string + objsx.string + prepsx.string + prepsx11.string]\n",
    "                                                            #verbsy = verbstemp\n",
    "\n",
    "                                                            if (len(subjs) > 0) and (len(objsy)) > 0  and (len(verbsy) > 0):\n",
    "                                                                for verb1 in verbsy:\n",
    "                                                                    for subj in subjs:\n",
    "                                                                        for obj1 in objsy:\n",
    "                                                                            yield (subj, verb1, obj1)   \n",
    "\n",
    "                                                    while len(objspo1) > 0 : objspo1.pop()\n",
    "                                    while len(prepsx1) > 0 : prepsx1.pop()    \n",
    "                        while len(preps) > 0 : preps.pop()        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #verb---xcomp(verb)---prep2---pobj11/pobj12\n",
    "    #                  ---dobj1/dobj2\n",
    "\n",
    "\n",
    "    def subject_verb_object_pattern11(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objs = []\n",
    "                objsy = []\n",
    "                verbsy = []\n",
    "                objs11 = []\n",
    "                objspo1 = []\n",
    "                prepsx1 = []\n",
    "                preps = []\n",
    "                verbstemp = []\n",
    "                cverbsy = []\n",
    "\n",
    "                # check if verb is having multiple prepositions which are verbs, which again have prepositions and prepositional objects and its conjunctions\n",
    "                verbsy = []\n",
    "                preps = _get_prepositions(verb)                    # check for any prepositions exist for that object\n",
    "                if len(preps) > 0:                                 # check atleast one preposition found\n",
    "                    for prepsx in preps:\n",
    "                        if prepsx.pos == VERB:\n",
    "                            prepsx1 = _get_prepositions(prepsx)                    # check for any prepositions exist for that object\n",
    "                            objs = get_objects_of_verb(prepsx)\n",
    "                            if len(prepsx1) > 0 and len(objs) > 0:                                 # check atleast one preposition found\n",
    "                                for objspx in objs:\n",
    "                                    for prepsx11 in prepsx1:\n",
    "                                        objspo1 = getprepobjects(prepsx11)    \n",
    "                                        if len(objspo1) > 0:                              # check for atleast one prepositional object found\n",
    "                                            for objspox1 in objspo1:\n",
    "                                                while len(objsy) > 0 : objsy.pop()\n",
    "                                                objsy.extend(objspo1)\n",
    "                                                objs11 = getobjconjtest(objspox1,nounconjl)          # get all conjunctions to given nounlist \n",
    "                                                if len(objs11) > 0:                         # if any conjunctions found for the object\n",
    "                                                    objsy.extend(objs11)                           # replace retrieved objects to objs list \n",
    "                                                    objsy = list(set(objsy))\n",
    "                                                objsy = replace_objs_with_compound_objs(objsy,sent)\n",
    "\n",
    "                                                \"\"\" Replace verbs with conjunction verbs\n",
    "                                                \"\"\"\n",
    "                                                while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                                while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                                conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                                conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                                if len(conjverb) > 0:\n",
    "                                                    cverbsy.extend(conjverb)\n",
    "                                                if len(conjnoun) > 0:\n",
    "                                                    cverbsy.extend(conjnoun)\n",
    "\n",
    "                                                cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                                cverbsy = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                                verbx   = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                                if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "                                                prepsxz = replaceverb_withauxillaryverb(prepsx,sent)\n",
    "                                                objspxz = replaceobj_withcompoundobj(objspx,sent)\n",
    "\n",
    "                                                if len(cverbsy) > 1:\n",
    "                                                    for cverbsy1 in cverbsy:\n",
    "                                                        verbstemp.extend([cverbsy1 + prepsxz + objspxz.string  + prepsx11.string])\n",
    "                                                else:\n",
    "                                                    verbstemp = [verbx + prepsxz + objspxz.string + prepsx11.string]\n",
    "                                                verbsy = verbstemp        \n",
    "\n",
    "                                                #verbstemp = [verb.string + prepsx.string + prepsx11.string]\n",
    "                                                #verbsy = verbstemp\n",
    "\n",
    "                                                if (len(subjs) > 0) and (len(objsy)) > 0  and (len(verbsy) > 0):\n",
    "                                                    for verb1 in verbsy:\n",
    "                                                        for subj in subjs:\n",
    "                                                            for obj1 in objsy:\n",
    "                                                                yield (subj, verb1, obj1)   \n",
    "\n",
    "                                            while len(objspo1) > 0 : objspo1.pop()\n",
    "                                while len(prepsx1) > 0 : prepsx1.pop()    \n",
    "                    while len(preps) > 0 : preps.pop()\n",
    "\n",
    "\n",
    "    #verb---xcomp(verb)---dobj1/pobj2\n",
    "\n",
    "    def subject_verb_object_pattern12(doc):\n",
    "\n",
    "        if isinstance(doc, SpacySpan):\n",
    "            sents = [doc]\n",
    "        else:  # textacy.Doc or spacy.Doc\n",
    "            sents = doc.sents\n",
    "\n",
    "        for sent in sents:\n",
    "            start_i = sent[0].i\n",
    "\n",
    "            nounconjl = get_all_noun_conjunctions(sent)                   # get all noun conjunctions in the given document\n",
    "            verbconjl = get_all_verb_conjunctions(sent)                   # get all verb conjunctions in the given document\n",
    "            subjsa = get_subjects_of_sent(sent)                          # get all subjects in a sentence\n",
    "\n",
    "            verbs = []\n",
    "            while len(verbs) > 0 : verbs.pop()\n",
    "            verbs = spacy_utils.get_main_verbs_of_sent(sent)\n",
    "            \"\"\"\n",
    "            Algorithm logic to extract non-verbs treated as verbs\n",
    "            1. Get all the nouns from the sentence\n",
    "            2. for every noun check if either subject or object exists to it \n",
    "            3. If exists then add noun to the verbs list\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            for verb in verbs:\n",
    "                \"\"\"\n",
    "                Algorithm logic to extract subjects of the verb\n",
    "\n",
    "                1. Check for any subjects exists for the given verb\n",
    "                2. If no subjects exists then get the main subject of the sentence as the subject\n",
    "                3. check if any conjunctions exists to the subject, if conjunctions exist add conjunctions to the subject\n",
    "                4. check if any prepositions exists for the subjects, if exists then extract prepositional subjects to the sentence\n",
    "                       check for any conjunctions exists for prepositional objects, if present then add all the subjects to subject list\n",
    "                \"\"\"\n",
    "\n",
    "                subjs = getsubjects_ofthe_verb(verb,sent)\n",
    "\n",
    "                \"\"\"\n",
    "                   Algorithm logic to extract objects of the verb\n",
    "\n",
    "                   1. Check for any objects exists for the given verb\n",
    "                   2. check if any conjunctions exists to the object, if conjunctions exist add conjunctions to the object list\n",
    "                   3. check if any prepositions exists for the objects, if exists then extract prepositional objects to the sentence\n",
    "                      check for any conjunctions exists for prepositional objects, if present then add all the objects to object list\n",
    "                \"\"\"               \n",
    "                xcompverb = getxcomp_ofthe_verb(verb,sent)   # get xcomp (open clausal compliment) of verb if exist\n",
    "                objs = []\n",
    "                objsy = []\n",
    "                verbsy = []\n",
    "                objs11 = []\n",
    "                objspo1 = []\n",
    "                prepsx1 = []\n",
    "                preps = []\n",
    "                verbstemp = []\n",
    "                cverbsy = []\n",
    "\n",
    "                # check if verb is having multiple prepositions which are verbs, which again have prepositions and prepositional objects and its conjunctions\n",
    "                verbsy = []\n",
    "                preps = _get_prepositions(verb)                    # check for any prepositions exist for that object\n",
    "                if len(preps) > 0:                                 # check atleast one preposition found\n",
    "                    for prepsx in preps:\n",
    "                        if prepsx.pos == VERB:\n",
    "                                    objs =  get_objects_of_verb(prepsx)\n",
    "                                    if len(objs) > 0:                              # check for atleast one prepositional object found\n",
    "                                        for objspox1 in objs:\n",
    "                                            while len(objsy) > 0 : objsy.pop()\n",
    "                                            objs11 = getobjconjtest(objspox1,nounconjl)          # get all conjunctions to given nounlist \n",
    "                                            if len(objs11) > 0:                         # if any conjunctions found for the object\n",
    "                                                objsy.extend(objs11)                           # replace retrieved objects to objs list \n",
    "                                                objsy = list(set(objsy))\n",
    "                                            objsy = replace_objs_with_compound_objs(objsy,sent)\n",
    "\n",
    "                                            \"\"\" Replace verbs with conjunction verbs\n",
    "                                            \"\"\"\n",
    "                                            while len(cverbsy) > 0 : cverbsy.pop()\n",
    "                                            while len(verbstemp) > 0 : verbstemp.pop()\n",
    "                                            conjverb = getobjconjtest(verb,verbconjl)\n",
    "                                            conjnoun = getobjconjtest(verb,nounconjl)\n",
    "                                            if len(conjverb) > 0:\n",
    "                                                cverbsy.extend(conjverb)\n",
    "                                            if len(conjnoun) > 0:\n",
    "                                                cverbsy.extend(conjnoun)\n",
    "\n",
    "                                            cverbsy = verbswithdobjs(verb,cverbsy,sent)\n",
    "\n",
    "                                            cverbsy = replace_verbs_with_auxillary_verbs(verb,cverbsy,sent)\n",
    "                                            verbx    = replaceverb_withauxillaryverb(verb,sent)\n",
    "                                            if len(xcompverb) > 0: verbx = xcompverb[0]\n",
    "                                            prepsxz    = replaceverb_withauxillaryverb(prepsx,sent)\n",
    "\n",
    "                                            if len(cverbsy) > 1:\n",
    "                                                for cverbsy1 in cverbsy:\n",
    "                                                    verbstemp.extend([cverbsy1 + prepsxz  ])\n",
    "                                            else:\n",
    "                                                verbstemp = [verbx + prepsxz  ]\n",
    "                                            verbsy = verbstemp        \n",
    "\n",
    "                                            #verbstemp = [verb.string + prepsx.string + prepsx11.string]\n",
    "                                            #verbsy = verbstemp\n",
    "\n",
    "                                            if (len(subjs) > 0) and (len(objsy)) > 0  and (len(verbsy) > 0):\n",
    "                                                for verb1 in verbsy:\n",
    "                                                    for subj in subjs:\n",
    "                                                        for obj1 in objsy:\n",
    "                                                            yield (subj, verb1, obj1)   \n",
    "\n",
    "                    while len(preps) > 0 : preps.pop()\n",
    "\n",
    "# import pandas\n",
    "# nlp = spacy.load(\"en\")\n",
    "\n",
    "# df = pandas.read_excel('C:\\\\Users\\\\MEI3KOR\\\\Desktop\\\\vv.xlsx', sheetname='Sheet4')\n",
    "# df.head()\n",
    "\n",
    "    tripletrows = []\n",
    "    dd1 = []\n",
    "    dd = []\n",
    "    #document = 'rama killed ravana'\n",
    "    # for index, row in df.iterrows():\n",
    "    doc1 = nlp(document)\n",
    "    sent = list(doc1.sents)\n",
    "    for line in sent:\n",
    "        line = line.text.lower()\n",
    "        doc = nlp(line)\n",
    "        triples1  = list(set(subject_verb_object_pattern1(doc)))\n",
    "        triples2  = list(set(subject_verb_object_pattern2(doc)))\n",
    "        triples3  = list(set(subject_verb_object_pattern3(doc)))\n",
    "        triples4  = list(set(subject_verb_object_pattern4(doc)))\n",
    "        triples5  = list(set(subject_verb_object_pattern5(doc)))\n",
    "        triples6  = list(set(subject_verb_object_pattern6(doc)))\n",
    "        triples7  = list(set(subject_verb_object_pattern7(doc)))\n",
    "        triples8  = list(set(subject_verb_object_pattern8(doc)))\n",
    "        triples9  = list(set(subject_verb_object_pattern9(doc)))\n",
    "        triples10 = list(set(subject_verb_object_pattern10(doc)))\n",
    "        triples11 = list(set(subject_verb_object_pattern11(doc)))\n",
    "        triples12 = list(set(subject_verb_object_pattern12(doc)))\n",
    "        triples   = list(set(triples1 + triples2 + triples3 + triples4  + triples5  + triples6 +\n",
    "                             triples7 + triples8 + triples9 + triples10 + triples11 + triples12))\n",
    "         \n",
    "        dd = [list(xx) for xx in triples]\n",
    "        \n",
    "        Sentence  = line\n",
    "        for d in dd:\n",
    "            \n",
    "            Entity1   = d[0]\n",
    "            Relation  = d[1]\n",
    "            Entity2   = d[2]\n",
    "            \n",
    "            tripletrows.append([Entity1, Relation, Entity2, Sentence])\n",
    "            \n",
    "    triplesdf = pd.DataFrame(tripletrows, columns=['Entity1', 'Relation', 'Entity2','Sentence'])\n",
    "    fdf = triplesdf.drop(['Sentence'], axis=1)\n",
    "    temp=[]\n",
    "\n",
    "    for row in fdf.iterrows():\n",
    "        index, data = row\n",
    "        temp.append(data.tolist())\n",
    "        \n",
    "    return temp\n",
    "    #triplesdf.to_csv('C:\\\\Users\\\\MEI3KOR\\\\Desktop\\\\demo.csv',encoding='utf-8')\n",
    "\n",
    "#writer.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"A user should be able to conduct a search by providing either restaurant name, restaurant description, restaurant address, restaurant type or restaurant menu in the free-text search field.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = 'rama killed ravana. Sita is wife of rama.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"I will accept your offer or decline it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"In the backyard, the dog barked and howled at the cat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"The dog lived in the garden, but the cat, who was smarter, lived inside the house.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"I enjoyed the apple pie that you bought for me.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Anushka is one of the many celebrities who are part of Prime Minister Narendra Modi's Swachh Bharat Abhiyan, a plan that aims to ensure positive advocacy to ensure Indians shun habits like littering on the roads or public spaces, apart from ending open defecation in the country.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"The system displays the user account information associated with this account and requests the administrator to edit the user account, password or contact email address.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['system ', 'requests to edit ', email address],\n",
       " ['system ', 'requests ', to edit],\n",
       " ['account information ', 'associated with ', account],\n",
       " ['system ', 'requests ', administrator],\n",
       " ['system ', 'requests to edit ', user account],\n",
       " ['system ', 'displays ', account information],\n",
       " ['system ', 'requests to edit ', password]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbieproc(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = verbieproc('rama killed ravana. Sita is wife of rama.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Sentence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]\n",
    "\n",
    "for row in df.iterrows():\n",
    "    index, data = row\n",
    "    temp.append(data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['rama ', 'killed ', ravana],\n",
       " ['sita ', 'is wife of ', rama],\n",
       " ['sita ', 'is ', wife]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
